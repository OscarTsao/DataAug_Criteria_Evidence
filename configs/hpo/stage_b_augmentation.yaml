# HPO Stage B: Augmentation-Only Optimization
#
# This stage optimizes augmentation hyperparameters ONLY, using the
# best baseline model configuration from Stage A.
#
# Prerequisites: Stage A must complete first
#
# Usage:
#   python scripts/tune_max.py --config-name stage_b_augmentation \
#       --baseline-config outputs/hpo_stage_a/best_config.yaml

# @package _global_

hpo:
  # Study configuration
  study_name: "stage_b_augmentation"
  n_trials: 100
  timeout_hours: 48

  # Optimization direction
  direction: "maximize"
  metric: "val_f1_macro"

  # Load baseline model config from Stage A
  baseline_config_path: "outputs/hpo_stage_a/best_config.yaml"

  # Search space: ONLY augmentation parameters
  # Model parameters are LOCKED from baseline config
  search_space:
    # Augmentation master switch
    augmentation_enabled:
      type: "categorical"
      choices: [true, false]  # Include baseline comparison

    # Augmentation scope
    augmentation_scope:
      type: "categorical"
      choices: ["train_only", "all"]

    # Augmentation probability
    augmentation_p_apply:
      type: "uniform"
      low: 0.05
      high: 0.30

    # Number of operations per sample
    augmentation_ops_per_sample:
      type: "int"
      low: 1
      high: 2

    # Maximum word replacement ratio
    augmentation_max_replace_ratio:
      type: "uniform"
      low: 0.1
      high: 0.5

    # Augmentation methods selection
    # Enable/disable specific augmentation techniques
    aug_method_synonym:
      type: "categorical"
      choices: [true, false]

    aug_method_contextual:
      type: "categorical"
      choices: [true, false]

    aug_method_char_swap:
      type: "categorical"
      choices: [true, false]

    aug_method_spelling:
      type: "categorical"
      choices: [true, false]

  # Constraints: Ensure valid configurations
  constraints:
    # At least one method must be enabled if augmentation is enabled
    - "not augmentation_enabled or (aug_method_synonym or aug_method_contextual or aug_method_char_swap or aug_method_spelling)"

    # Maximum 2 methods enabled simultaneously
    - "sum([aug_method_synonym, aug_method_contextual, aug_method_char_swap, aug_method_spelling]) <= 2"

  # Pruning configuration (more aggressive for augmentation)
  pruning:
    enabled: true
    patience: 3
    min_delta: 0.005
    warmup_steps: 2

  # Sampler configuration
  sampler:
    type: "TPESampler"
    n_startup_trials: 20  # More startup trials for augmentation
    multivariate: true

# Notes:
# - Model architecture parameters (model_name, learning_rate, etc.) are LOCKED
# - Only augmentation parameters are optimized
# - Baseline (augmentation_enabled=false) is always included for comparison
## HPO Stage B â€” Augmentation sweep
#
# Search over augmentation-only parameters on top of a strong baseline study.
